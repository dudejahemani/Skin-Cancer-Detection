{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, LeakyReLU, UpSampling2D, Conv2D, BatchNormalization, Dropout, Flatten\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Acitinic Keratosis: 500 images loaded.\n",
      "Class Basal Cell Carcinoma: 500 images loaded.\n",
      "Class Melanoma: 505 images loaded.\n",
      "Class Nevus: 500 images loaded.\n",
      "Class Pigmented Benign Keratosis: 500 images loaded.\n",
      "Class Seborrheic Keratosis: 500 images loaded.\n",
      "Class Acitinic Keratosis is underrepresented (500 images). Generating 500 synthetic images using WGAN-GP...\n",
      "Epoch 10/200 | D loss: -72.1756 | G loss: -229.5781 | D real: 314.2914 | D fake: 215.9108\n",
      "Epoch 20/200 | D loss: -13.9337 | G loss: 26.3479 | D real: 21.5690 | D fake: 3.9101\n",
      "Epoch 30/200 | D loss: 18.7225 | G loss: -99.0958 | D real: 120.2775 | D fake: 135.5092\n",
      "Epoch 40/200 | D loss: -0.2838 | G loss: -35.1240 | D real: 24.1869 | D fake: 23.4068\n",
      "Epoch 50/200 | D loss: -3.4967 | G loss: 68.1900 | D real: -44.2136 | D fake: -47.8445\n",
      "Epoch 60/200 | D loss: -2.9592 | G loss: 36.9135 | D real: -47.8217 | D fake: -50.9026\n",
      "Epoch 70/200 | D loss: -14.3288 | G loss: 105.3916 | D real: -102.2248 | D fake: -117.4342\n",
      "Epoch 80/200 | D loss: -0.4979 | G loss: 15.9489 | D real: -8.6965 | D fake: -9.2613\n",
      "Epoch 90/200 | D loss: -0.6697 | G loss: 73.4704 | D real: -67.0852 | D fake: -67.8122\n",
      "Epoch 100/200 | D loss: 4.5703 | G loss: -50.2267 | D real: 61.4412 | D fake: 65.9591\n",
      "Epoch 110/200 | D loss: -0.9994 | G loss: 57.0814 | D real: -59.3997 | D fake: -60.5235\n",
      "Epoch 120/200 | D loss: 6.3427 | G loss: 20.3721 | D real: -28.5221 | D fake: -22.2043\n",
      "Epoch 130/200 | D loss: -0.6617 | G loss: 88.1363 | D real: -93.8048 | D fake: -94.7022\n",
      "Epoch 140/200 | D loss: 0.9255 | G loss: -77.5544 | D real: 80.9093 | D fake: 81.6894\n",
      "Epoch 150/200 | D loss: -2.4372 | G loss: 48.6863 | D real: -55.0610 | D fake: -57.7257\n",
      "Epoch 160/200 | D loss: -1.8978 | G loss: 120.5466 | D real: -96.6437 | D fake: -98.7304\n",
      "Epoch 170/200 | D loss: 0.0897 | G loss: -135.4436 | D real: 147.3356 | D fake: 146.4370\n",
      "Epoch 180/200 | D loss: 0.4006 | G loss: 48.0930 | D real: -50.7520 | D fake: -50.3708\n",
      "Epoch 190/200 | D loss: 10.4123 | G loss: 47.8828 | D real: -46.0198 | D fake: -35.9965\n",
      "Epoch 200/200 | D loss: 4.6929 | G loss: -43.2526 | D real: 41.6858 | D fake: 46.3519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating synthetic for Acitinic Keratosis: 100%|██████████| 500/500 [00:31<00:00, 15.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Basal Cell Carcinoma is underrepresented (500 images). Generating 500 synthetic images using WGAN-GP...\n",
      "Epoch 10/200 | D loss: -70.8176 | G loss: -160.3927 | D real: 227.6046 | D fake: 134.3074\n",
      "Epoch 20/200 | D loss: -49.5050 | G loss: -243.3641 | D real: 314.1735 | D fake: 250.2377\n",
      "Epoch 30/200 | D loss: -18.0581 | G loss: -185.6517 | D real: 211.6005 | D fake: 188.7256\n",
      "Epoch 40/200 | D loss: -7.9396 | G loss: -16.4537 | D real: 46.6399 | D fake: 37.2425\n",
      "Epoch 50/200 | D loss: -2.3608 | G loss: -31.3196 | D real: 41.8118 | D fake: 39.2409\n",
      "Epoch 60/200 | D loss: -5.8494 | G loss: 9.7903 | D real: 3.6513 | D fake: -2.3068\n",
      "Epoch 70/200 | D loss: -6.9012 | G loss: -26.5474 | D real: 20.6298 | D fake: 13.7262\n",
      "Epoch 80/200 | D loss: -16.3920 | G loss: 159.5298 | D real: -148.0258 | D fake: -166.6843\n",
      "Epoch 90/200 | D loss: -6.9733 | G loss: -92.5928 | D real: 105.6634 | D fake: 97.9364\n",
      "Epoch 100/200 | D loss: -12.0510 | G loss: 54.3651 | D real: -53.9524 | D fake: -68.9087\n",
      "Epoch 110/200 | D loss: -0.6496 | G loss: -5.6235 | D real: 16.6811 | D fake: 15.9955\n",
      "Epoch 120/200 | D loss: -2.8052 | G loss: 8.1250 | D real: -1.0088 | D fake: -4.3086\n",
      "Epoch 130/200 | D loss: -2.4691 | G loss: -22.7761 | D real: 18.2969 | D fake: 15.6294\n",
      "Epoch 140/200 | D loss: 20.6093 | G loss: 199.6552 | D real: -248.5837 | D fake: -232.4648\n",
      "Epoch 150/200 | D loss: 1.1158 | G loss: -20.9069 | D real: 20.3109 | D fake: 21.1042\n",
      "Epoch 160/200 | D loss: -8.1897 | G loss: 63.9200 | D real: -50.0457 | D fake: -59.9896\n",
      "Epoch 170/200 | D loss: -1.5988 | G loss: 22.9312 | D real: -9.1455 | D fake: -10.9981\n",
      "Epoch 180/200 | D loss: -6.6960 | G loss: 47.2181 | D real: -47.2838 | D fake: -54.1426\n",
      "Epoch 190/200 | D loss: 9.6018 | G loss: 108.3539 | D real: -121.4392 | D fake: -112.6722\n",
      "Epoch 200/200 | D loss: -0.1809 | G loss: -66.5910 | D real: 66.6733 | D fake: 66.1332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating synthetic for Basal Cell Carcinoma: 100%|██████████| 500/500 [00:34<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Melanoma is underrepresented (505 images). Generating 495 synthetic images using WGAN-GP...\n",
      "Epoch 10/200 | D loss: -66.4920 | G loss: 22.3503 | D real: 64.7679 | D fake: -30.8244\n",
      "Epoch 20/200 | D loss: -22.4554 | G loss: -171.9263 | D real: 207.1654 | D fake: 174.7980\n",
      "Epoch 30/200 | D loss: -6.6718 | G loss: -53.8908 | D real: 52.7818 | D fake: 44.5159\n",
      "Epoch 40/200 | D loss: -2.3597 | G loss: 40.9251 | D real: -33.7176 | D fake: -36.6604\n",
      "Epoch 50/200 | D loss: -1.6278 | G loss: 16.8081 | D real: 5.7616 | D fake: 3.9721\n",
      "Epoch 60/200 | D loss: 2.7489 | G loss: -161.0603 | D real: 153.6126 | D fake: 156.0046\n",
      "Epoch 70/200 | D loss: 5.0018 | G loss: -21.5962 | D real: 9.2065 | D fake: 14.1988\n",
      "Epoch 80/200 | D loss: -2.6697 | G loss: -6.0928 | D real: 21.9980 | D fake: 19.2773\n",
      "Epoch 90/200 | D loss: -2.7046 | G loss: 1.7367 | D real: -6.2399 | D fake: -8.9578\n",
      "Epoch 100/200 | D loss: -3.7322 | G loss: 45.4231 | D real: -30.1774 | D fake: -34.1938\n",
      "Epoch 110/200 | D loss: -1.6521 | G loss: -56.1988 | D real: 54.5445 | D fake: 52.6488\n",
      "Epoch 120/200 | D loss: -6.1351 | G loss: 47.3502 | D real: -35.9707 | D fake: -42.4234\n",
      "Epoch 130/200 | D loss: 0.0559 | G loss: 6.0295 | D real: -7.2814 | D fake: -7.4041\n",
      "Epoch 140/200 | D loss: -7.9865 | G loss: -205.8997 | D real: 196.9485 | D fake: 187.1204\n",
      "Epoch 150/200 | D loss: -14.8300 | G loss: 146.6394 | D real: -122.1043 | D fake: -138.8413\n",
      "Epoch 160/200 | D loss: -1.2597 | G loss: -219.9582 | D real: 247.3324 | D fake: 241.5955\n",
      "Epoch 170/200 | D loss: -6.6749 | G loss: 146.8675 | D real: -135.6655 | D fake: -144.8772\n",
      "Epoch 180/200 | D loss: 4.5134 | G loss: 2.3716 | D real: 7.9668 | D fake: 11.0525\n",
      "Epoch 190/200 | D loss: -10.4871 | G loss: 1.2742 | D real: 8.4747 | D fake: -2.2006\n",
      "Epoch 200/200 | D loss: -1.5198 | G loss: -53.6367 | D real: 50.1943 | D fake: 48.5353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating synthetic for Melanoma: 100%|██████████| 495/495 [01:30<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Nevus is underrepresented (500 images). Generating 500 synthetic images using WGAN-GP...\n",
      "Epoch 10/200 | D loss: -118.2937 | G loss: -591.7361 | D real: 808.9854 | D fake: 613.9547\n",
      "Epoch 20/200 | D loss: -107.5850 | G loss: -467.2721 | D real: 559.3958 | D fake: 416.6608\n",
      "Epoch 30/200 | D loss: -32.8508 | G loss: -205.6419 | D real: 263.1173 | D fake: 213.3132\n",
      "Epoch 40/200 | D loss: -39.5551 | G loss: -113.0780 | D real: 179.9140 | D fake: 124.7859\n",
      "Epoch 50/200 | D loss: -34.9384 | G loss: -35.5683 | D real: 95.4747 | D fake: 43.8785\n",
      "Epoch 60/200 | D loss: -44.4388 | G loss: -93.8027 | D real: 141.0623 | D fake: 78.9300\n",
      "Epoch 70/200 | D loss: -37.2540 | G loss: -29.6684 | D real: 108.3107 | D fake: 54.9095\n",
      "Epoch 80/200 | D loss: -31.7776 | G loss: -148.3019 | D real: 172.0252 | D fake: 126.7090\n",
      "Epoch 90/200 | D loss: -12.9466 | G loss: -150.0097 | D real: 150.4559 | D fake: 135.7314\n",
      "Epoch 100/200 | D loss: 0.2004 | G loss: -107.6481 | D real: 106.3625 | D fake: 106.5011\n",
      "Epoch 110/200 | D loss: -1.3100 | G loss: 14.6927 | D real: -0.7112 | D fake: -2.5548\n",
      "Epoch 120/200 | D loss: 8.8183 | G loss: -72.0607 | D real: 76.8518 | D fake: 85.5422\n",
      "Epoch 130/200 | D loss: -7.6067 | G loss: 116.5978 | D real: -101.9306 | D fake: -111.6238\n",
      "Epoch 140/200 | D loss: -30.1618 | G loss: -114.7061 | D real: 122.3195 | D fake: 81.5962\n",
      "Epoch 150/200 | D loss: -3.2135 | G loss: -103.9905 | D real: 108.2035 | D fake: 104.7193\n",
      "Epoch 160/200 | D loss: 3.4396 | G loss: 78.7315 | D real: -89.3298 | D fake: -86.5958\n",
      "Epoch 170/200 | D loss: 0.3934 | G loss: -37.4044 | D real: 33.0184 | D fake: 33.3934\n",
      "Epoch 180/200 | D loss: 1.0508 | G loss: -25.2753 | D real: 17.2255 | D fake: 18.2525\n",
      "Epoch 190/200 | D loss: -7.5658 | G loss: 121.4860 | D real: -109.4005 | D fake: -117.6267\n",
      "Epoch 200/200 | D loss: -5.8598 | G loss: -115.3930 | D real: 125.4628 | D fake: 119.3191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating synthetic for Nevus: 100%|██████████| 500/500 [01:28<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Pigmented Benign Keratosis is underrepresented (500 images). Generating 500 synthetic images using WGAN-GP...\n",
      "Epoch 10/200 | D loss: -97.9839 | G loss: -496.4385 | D real: 677.6969 | D fake: 515.7761\n",
      "Epoch 20/200 | D loss: -35.4611 | G loss: -365.9973 | D real: 444.9709 | D fake: 386.2709\n",
      "Epoch 30/200 | D loss: -10.5093 | G loss: -251.9979 | D real: 282.9178 | D fake: 266.9203\n",
      "Epoch 40/200 | D loss: -11.0351 | G loss: -153.8676 | D real: 162.9816 | D fake: 151.2151\n",
      "Epoch 50/200 | D loss: -5.4445 | G loss: -199.2551 | D real: 211.6152 | D fake: 204.3473\n",
      "Epoch 60/200 | D loss: -8.0212 | G loss: 46.7191 | D real: -33.9126 | D fake: -42.5141\n",
      "Epoch 70/200 | D loss: -6.5037 | G loss: -13.0667 | D real: 21.0659 | D fake: 13.2809\n",
      "Epoch 80/200 | D loss: 1.6969 | G loss: -97.7358 | D real: 116.4653 | D fake: 117.5272\n",
      "Epoch 90/200 | D loss: -1.8640 | G loss: -100.7233 | D real: 121.3928 | D fake: 119.5195\n",
      "Epoch 100/200 | D loss: 3.9728 | G loss: -59.5882 | D real: 69.0770 | D fake: 71.9130\n",
      "Epoch 110/200 | D loss: -0.8535 | G loss: -74.3752 | D real: 73.3756 | D fake: 72.3954\n",
      "Epoch 120/200 | D loss: -6.7848 | G loss: -78.3387 | D real: 68.6760 | D fake: 61.3954\n",
      "Epoch 130/200 | D loss: -0.9470 | G loss: -36.8889 | D real: 30.5801 | D fake: 29.5322\n",
      "Epoch 140/200 | D loss: -2.1852 | G loss: 203.3707 | D real: -205.2868 | D fake: -208.9738\n",
      "Epoch 150/200 | D loss: 3.2230 | G loss: -63.3646 | D real: 66.9554 | D fake: 70.1194\n",
      "Epoch 160/200 | D loss: -2.4313 | G loss: -40.9373 | D real: 33.5497 | D fake: 31.1069\n",
      "Epoch 170/200 | D loss: -1.8880 | G loss: -17.2465 | D real: 23.4134 | D fake: 21.3511\n",
      "Epoch 180/200 | D loss: -4.5127 | G loss: -72.0497 | D real: 70.6182 | D fake: 66.0083\n",
      "Epoch 190/200 | D loss: -2.1578 | G loss: -64.4854 | D real: 63.7870 | D fake: 61.4235\n",
      "Epoch 200/200 | D loss: 7.4461 | G loss: 98.8173 | D real: -112.4476 | D fake: -105.7209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating synthetic for Pigmented Benign Keratosis: 100%|██████████| 500/500 [00:29<00:00, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Seborrheic Keratosis is underrepresented (500 images). Generating 500 synthetic images using WGAN-GP...\n",
      "Epoch 10/200 | D loss: -89.6475 | G loss: -192.6721 | D real: 370.7676 | D fake: 225.5564\n",
      "Epoch 20/200 | D loss: -63.3904 | G loss: -61.6199 | D real: 107.4305 | D fake: 23.4460\n",
      "Epoch 30/200 | D loss: -15.6448 | G loss: -132.6700 | D real: 177.6565 | D fake: 152.4722\n",
      "Epoch 40/200 | D loss: -5.6655 | G loss: -71.5793 | D real: 73.4076 | D fake: 63.0964\n",
      "Epoch 50/200 | D loss: -2.0773 | G loss: 31.9673 | D real: -49.3456 | D fake: -51.5914\n",
      "Epoch 60/200 | D loss: -2.2983 | G loss: -12.9114 | D real: 29.3045 | D fake: 26.8682\n",
      "Epoch 70/200 | D loss: -5.0559 | G loss: 16.8556 | D real: -35.7695 | D fake: -41.1390\n",
      "Epoch 80/200 | D loss: -14.1765 | G loss: 61.8498 | D real: -13.4850 | D fake: -28.8504\n",
      "Epoch 90/200 | D loss: -6.3774 | G loss: -67.3154 | D real: 81.1562 | D fake: 74.7717\n",
      "Epoch 100/200 | D loss: -2.3967 | G loss: 71.3788 | D real: -62.1898 | D fake: -64.6292\n",
      "Epoch 110/200 | D loss: -1.9990 | G loss: -40.6013 | D real: 28.0334 | D fake: 26.0071\n",
      "Epoch 120/200 | D loss: -1.5548 | G loss: -7.1031 | D real: 22.7987 | D fake: 20.9923\n",
      "Epoch 130/200 | D loss: -6.0577 | G loss: -24.9887 | D real: 27.5289 | D fake: 20.3245\n",
      "Epoch 140/200 | D loss: 0.2459 | G loss: 80.7131 | D real: -75.2309 | D fake: -75.1744\n",
      "Epoch 150/200 | D loss: -8.0945 | G loss: -110.6042 | D real: 96.2188 | D fake: 88.0684\n",
      "Epoch 160/200 | D loss: -0.9276 | G loss: 97.2244 | D real: -87.2497 | D fake: -88.6658\n",
      "Epoch 170/200 | D loss: -12.5757 | G loss: 9.9486 | D real: 8.2168 | D fake: -7.1437\n",
      "Epoch 180/200 | D loss: -15.0532 | G loss: -8.2326 | D real: 8.6802 | D fake: -8.3065\n",
      "Epoch 190/200 | D loss: -1.0516 | G loss: 116.6479 | D real: -109.9046 | D fake: -111.0523\n",
      "Epoch 200/200 | D loss: -4.9422 | G loss: -115.5576 | D real: 119.1756 | D fake: 113.9722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating synthetic for Seborrheic Keratosis: 100%|██████████| 500/500 [00:31<00:00, 15.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation complete!\n",
      "Augmented dataset size: 6000 images\n"
     ]
    }
   ],
   "source": [
    "# Allow GPU memory growth\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "latent_dim = 100\n",
    "target_count = 1000   # Desired images per class\n",
    "img_size = 224        # Resize images to 224x224\n",
    "\n",
    "# Define your classes and dataset folder\n",
    "categories = ['Acitinic Keratosis', 'Basal Cell Carcinoma', 'Melanoma', \n",
    "              'Nevus', 'Pigmented Benign Keratosis', 'Seborrheic Keratosis']\n",
    "data_path = 'Skin Cancer Dataset'\n",
    "\n",
    "# Load images for each class (in [0,255] uint8)\n",
    "class_data = {}\n",
    "for cat in categories:\n",
    "    folder_path = os.path.join(data_path, cat)\n",
    "    images = []\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                try:\n",
    "                    img = cv2.resize(img, (img_size, img_size))\n",
    "                    images.append(img)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_path}: {e}\")\n",
    "    else:\n",
    "        print(f\"Warning: Folder {folder_path} does not exist.\")\n",
    "    class_data[cat] = images\n",
    "    print(f\"Class {cat}: {len(images)} images loaded.\")\n",
    "\n",
    "\n",
    "# Improved Generator: Upsamples from a 14x14 feature map to 224x224\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    n_nodes = 256 * 14 * 14\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((14, 14, 256)))\n",
    "    # Upsample to 28x28\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # Upsample to 56x56\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # Upsample to 112x112\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # Upsample to 224x224\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(32, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # Final convolution: output in [0,1]\n",
    "    model.add(Conv2D(3, kernel_size=3, padding='same', activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Improved Discriminator: Remove sigmoid so it outputs a raw score\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=img_shape, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))  # Linear output for WGAN\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_wgan_gp(class_images, latent_dim=latent_dim, epochs=200, batch_size=16, n_critic=5, lambda_gp=10.0):\n",
    "    img_shape = (img_size, img_size, 3)\n",
    "    generator = build_generator(latent_dim)\n",
    "    discriminator = build_discriminator(img_shape)\n",
    "    \n",
    "    d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n",
    "    g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n",
    "    \n",
    "    # Normalize real images from [0,255] to [0,1]\n",
    "    real_images = np.array(class_images, dtype=np.float32) / 255.0\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(real_images).shuffle(buffer_size=real_images.shape[0]).batch(batch_size, drop_remainder=True)\n",
    "    \n",
    "    @tf.function\n",
    "    def d_train_step(real_imgs):\n",
    "        batch_size_ = tf.shape(real_imgs)[0]\n",
    "        noise = tf.random.normal([batch_size_, latent_dim])\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_imgs = generator(noise, training=True)\n",
    "            real_validity = discriminator(real_imgs, training=True)\n",
    "            fake_validity = discriminator(fake_imgs, training=True)\n",
    "            \n",
    "            # Gradient penalty calculation\n",
    "            alpha = tf.random.uniform([batch_size_, 1, 1, 1], 0.0, 1.0)\n",
    "            interpolated = alpha * real_imgs + (1 - alpha) * fake_imgs\n",
    "            with tf.GradientTape() as tape_gp:\n",
    "                tape_gp.watch(interpolated)\n",
    "                interpolated_validity = discriminator(interpolated, training=True)\n",
    "            grads = tape_gp.gradient(interpolated_validity, [interpolated])[0]\n",
    "            grads = tf.reshape(grads, [batch_size_, -1])\n",
    "            grad_norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=1) + 1e-12)\n",
    "            gp = tf.reduce_mean((grad_norm - 1.0) ** 2)\n",
    "            \n",
    "            d_loss = tf.reduce_mean(fake_validity) - tf.reduce_mean(real_validity) + lambda_gp * gp\n",
    "        gradients = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "        d_optimizer.apply_gradients(zip(gradients, discriminator.trainable_variables))\n",
    "        return d_loss, tf.reduce_mean(real_validity), tf.reduce_mean(fake_validity)\n",
    "    \n",
    "    @tf.function\n",
    "    def g_train_step():\n",
    "        noise = tf.random.normal([batch_size, latent_dim])\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_imgs = generator(noise, training=True)\n",
    "            fake_validity = discriminator(fake_imgs, training=True)\n",
    "            g_loss = -tf.reduce_mean(fake_validity)\n",
    "        gradients = tape.gradient(g_loss, generator.trainable_variables)\n",
    "        g_optimizer.apply_gradients(zip(gradients, generator.trainable_variables))\n",
    "        return g_loss\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        # Run n_critic updates for discriminator per generator update\n",
    "        for _ in range(n_critic):\n",
    "            for real_batch in dataset.take(1):\n",
    "                d_loss, real_val, fake_val = d_train_step(real_batch)\n",
    "        g_loss = g_train_step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | D loss: {d_loss:.4f} | G loss: {g_loss:.4f} | D real: {real_val:.4f} | D fake: {fake_val:.4f}\")\n",
    "    return generator\n",
    "\n",
    "synthetic_data = defaultdict(list)\n",
    "synthetic_save_path = \"synthetic_data\"\n",
    "os.makedirs(synthetic_save_path, exist_ok=True)\n",
    "\n",
    "# For each class, if count < target_count, train WGAN-GP and generate synthetic images.\n",
    "for cat in categories:\n",
    "    count = len(class_data[cat])\n",
    "    if count < target_count:\n",
    "        diff = target_count - count\n",
    "        print(f\"Class {cat} is underrepresented ({count} images). Generating {diff} synthetic images using WGAN-GP...\")\n",
    "        gen_model = train_wgan_gp(class_data[cat], epochs=200, batch_size=16, n_critic=5, lambda_gp=10.0)\n",
    "        class_folder = os.path.join(synthetic_save_path, cat)\n",
    "        os.makedirs(class_folder, exist_ok=True)\n",
    "        for i in tqdm(range(diff), desc=f\"Generating synthetic for {cat}\"):\n",
    "            noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "            synth_img = gen_model.predict(noise, verbose=0)[0]\n",
    "            # Convert image from [0,1] float to [0,255] uint8\n",
    "            synth_img_uint8 = np.uint8(synth_img * 255)\n",
    "            synthetic_data[cat].append(synth_img_uint8)\n",
    "            cv2.imwrite(os.path.join(class_folder, f\"synthetic_{i}.png\"),\n",
    "                        cv2.cvtColor(synth_img_uint8, cv2.COLOR_RGB2BGR))\n",
    "    else:\n",
    "        print(f\"Class {cat} is sufficiently represented (count: {count}).\")\n",
    "\n",
    "# Combine original and synthetic data for augmentation\n",
    "augmented_data = []\n",
    "augmented_labels = []\n",
    "label_dict = {cat: idx for idx, cat in enumerate(categories)}\n",
    "for cat in categories:\n",
    "    imgs = class_data[cat]           # original images in [0,255]\n",
    "    syn_imgs = synthetic_data.get(cat, [])\n",
    "    total_imgs = imgs + syn_imgs\n",
    "    augmented_data.extend(total_imgs)\n",
    "    augmented_labels.extend([label_dict[cat]] * len(total_imgs))\n",
    "\n",
    "# Convert to NumPy arrays and normalize augmented images to [0,1]\n",
    "augmented_data = np.array(augmented_data, dtype=np.float32) / 255.0\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "print(\"Data augmentation complete!\")\n",
    "print(f\"Augmented dataset size: {augmented_data.shape[0]} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
